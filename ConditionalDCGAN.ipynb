{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ConditionalDCGAN.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/taikingyo/ConditionalDCGAN/blob/master/ConditionalDCGAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O3M_8GzncNfj",
        "colab_type": "text"
      },
      "source": [
        "# ConditionalDCGAN\n",
        "## 必要ライブラリのインポート"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5QzlMGaHa_2t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras as tfk\n",
        "from sklearn.utils import shuffle"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-V6fWRyIct86",
        "colab_type": "text"
      },
      "source": [
        "## クラス定義"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e4KLcW6ensRS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ConditionalDCGAN():\n",
        "  def __init__(self, img_rows, img_cols, img_channels, class_num, dim=100):\n",
        "    self.dim = dim\n",
        "    self.img_rows = img_rows\n",
        "    self.img_cols = img_cols\n",
        "    self.img_channels = img_channels\n",
        "    self.img_shape = (img_rows, img_cols, img_channels)\n",
        "    self.class_num = class_num\n",
        "    \n",
        "    self.generator = self.build_generator()\n",
        "    self.discriminator = self.build_discriminator()\n",
        "    self.discriminator.compile(loss='binary_crossentropy', optimizer=tfk.optimizers.Adam(0.0002, 0.5), metrics=['accuracy'])\n",
        "    self.combined = self.build_combined()\n",
        "    self.combined.compile(loss='binary_crossentropy', optimizer=tfk.optimizers.Adam(0.0002, 0.5))\n",
        "  \n",
        "  def build_generator(self):\n",
        "    f1, f2 = self.common_factor(self.img_rows, self.img_cols)\n",
        "    n_filter = 64 * 2 ** (len(f1) - 2)\n",
        "    \n",
        "    noise = tfk.Input(shape=(self.dim,), dtype='float32', name='img_seed')\n",
        "    label = tfk.Input(shape=(1,), dtype='int32', name='img_label')\n",
        "    \n",
        "    label_emb = tfk.layers.Embedding(input_dim=self.class_num, output_dim=self.dim)(label)\n",
        "    label_emb = tfk.layers.Flatten()(label_emb)\n",
        "    tensor = tfk.layers.Add()([noise, label_emb])\n",
        "    tensor = tfk.layers.Dense(n_filter * f1[-1] * f2[-1])(tensor)\n",
        "    tensor = tfk.layers.Reshape((f1[-1], f2[-1], n_filter))(tensor)\n",
        "    tensor = tfk.layers.BatchNormalization()(tensor)\n",
        "    n_filter = n_filter // 2\n",
        "    f1 = f1[:-1]\n",
        "    f2 = f2[:-1]\n",
        "    \n",
        "    for _ in range(len(f1) - 1):\n",
        "      tensor = tfk.layers.Conv2DTranspose(n_filter, 5, f1[-1], padding='same', activation='relu', kernel_initializer='glorot_normal')(tensor)\n",
        "      tensor = tfk.layers.BatchNormalization()(tensor)\n",
        "      n_filter = n_filter // 2\n",
        "      f1 = f1[:-1]\n",
        "      f2 = f2[:-1]\n",
        "    \n",
        "    images = tfk.layers.Conv2DTranspose(self.img_channels, 5, strides=(f1[0], f2[0]), padding='same', activation='tanh', kernel_initializer='glorot_normal')(tensor)\n",
        "    \n",
        "    model = tfk.models.Model(inputs=[noise, label], outputs=images)\n",
        "    #model.summary()\n",
        "    \n",
        "    return model\n",
        "  \n",
        "  def build_discriminator(self):\n",
        "    f1, f2 = self.common_factor(self.img_rows, self.img_cols)\n",
        "    h = self.img_rows\n",
        "    w = self.img_cols\n",
        "    n_filter = 64\n",
        "    \n",
        "    img = tfk.Input(shape=self.img_shape, dtype='float32', name='image')\n",
        "    label = tfk.Input(shape=(1,), dtype='int32', name='img_label')\n",
        "    \n",
        "    label_emb = tfk.layers.Embedding(input_dim=self.class_num, output_dim=np.prod(self.img_shape))(label)\n",
        "    label_emb = tfk.layers.Reshape((self.img_rows, self.img_cols, self.img_channels))(label_emb)\n",
        "    tensor = tfk.layers.Add()([img, label_emb])\n",
        "    \n",
        "    for _ in range(len(f1) - 1):\n",
        "      tensor = tfk.layers.Convolution2D(n_filter, kernel_size=5, strides=(f1[0], f2[0]), padding='same', kernel_initializer='glorot_normal')(tensor)\n",
        "      tensor = tfk.layers.LeakyReLU(0.2)(tensor)\n",
        "      n_filter *= 2\n",
        "      f1 = f1[1:]\n",
        "      f2 = f2[1:]\n",
        "      \n",
        "    tensor = tfk.layers.Flatten()(tensor)\n",
        "    tensor = tfk.layers.Dense(256)(tensor)\n",
        "    tensor = tfk.layers.LeakyReLU(0.2)(tensor)\n",
        "    tensor = tfk.layers.Dropout(0.5)(tensor)\n",
        "    valid = tfk.layers.Dense(1, activation='sigmoid')(tensor)\n",
        "    \n",
        "    model = tfk.models.Model(inputs=[img, label], outputs=valid)\n",
        "    #model.summary()\n",
        "    \n",
        "    return model\n",
        "  \n",
        "  def build_combined(self):\n",
        "    noise = tfk.Input(shape=(self.dim,), dtype='float32')\n",
        "    label = tfk.Input(shape=(1,), dtype='int32')\n",
        "    img = self.generator([noise, label])\n",
        "    self.discriminator.trainable = False\n",
        "    valid = self.discriminator([img, label])\n",
        "    \n",
        "    model = tfk.models.Model(inputs=[noise, label], outputs=valid)\n",
        "    \n",
        "    return model\n",
        "  \n",
        "  def train(self, x, y, epochs, batch_size=128):\n",
        "    half_batch = int(batch_size / 2)\n",
        "    steps = -(-x.shape[0] // half_batch)\n",
        "    \n",
        "    for epoch in range(epochs):\n",
        "      x_, y_ = shuffle(x, y)\n",
        "      \n",
        "      for step in range(steps):\n",
        "        start = step * half_batch\n",
        "        end = min(start + half_batch, x_.shape[0])\n",
        "        batch_ = end - start\n",
        "        \n",
        "        #train discriminator\n",
        "        \n",
        "        noise = np.random.normal(0, 1, (batch_, self.dim))\n",
        "        g_labels = np.random.randint(0, self.class_num, batch_)\n",
        "        g_images = self.generator.predict([noise, g_labels])\n",
        "        r_images = x_[start:end]\n",
        "        r_labels = y_[start:end]\n",
        "        \n",
        "        d_loss_real = self.discriminator.train_on_batch([r_images, r_labels], np.ones((batch_, 1)))\n",
        "        d_loss_fake = self.discriminator.train_on_batch([g_images, g_labels], np.zeros((batch_, 1)))\n",
        "        d_loss = np.add(d_loss_real, d_loss_fake) / 2\n",
        "        \n",
        "        #train generator\n",
        "        \n",
        "        noise = np.random.normal(0, 1, (batch_size, self.dim))\n",
        "        g_labels = np.random.randint(0, self.class_num, batch_size)\n",
        "        g_loss = self.combined.train_on_batch([noise, g_labels], np.ones((batch_size,)))\n",
        "        \n",
        "      print(\"%d [D loss: %f, acc: %.2f%%] [G loss: %f]\" % (epoch, d_loss[0], 100*d_loss[1], g_loss))\n",
        "      \n",
        "    self.show_imgs(100)\n",
        "        \n",
        "  def show_imgs(self, seed=None):\n",
        "    r, c = 5, 5\n",
        "    if seed is not None:\n",
        "      np.random.seed(seed)\n",
        "    noise = np.random.normal(0, 1, (r * c, self.dim))\n",
        "    label = np.arange(self.class_num)\n",
        "    rep = -int(-(r * c) // self.class_num)\n",
        "    label = np.tile(label, rep)[:r * c]\n",
        "    gen_imgs = self.generator.predict([noise, label])\n",
        "    gen_imgs = 0.5 * gen_imgs + 0.5\n",
        "    if(self.img_channels == 1):\n",
        "      gen_imgs = gen_imgs.reshape([r * c, self.img_rows, self.img_cols])\n",
        "    fig, axs = plt.subplots(r, c)\n",
        "    cnt = 0\n",
        "    for i in range(r):\n",
        "      for j in range(c):\n",
        "        axs[i, j].imshow(gen_imgs[cnt])\n",
        "        axs[i, j].axis('off')\n",
        "        cnt += 1\n",
        "        \n",
        "  def common_factor(self, x1, x2):\n",
        "    #自動調整の為の公約数の計算\n",
        "    f1 = []\n",
        "    f2 = []\n",
        "    \n",
        "    b = 2\n",
        "    while b < x1 and b < x2:\n",
        "      if x1 % b == 0 and x2 % b == 0:\n",
        "        f1.append(b)\n",
        "        f2.append(b)\n",
        "        x1 = x1 // b\n",
        "        x2 = x2 // b\n",
        "      else:\n",
        "        b += 1\n",
        "    f1.append(x1)\n",
        "    f2.append(x2)\n",
        "    \n",
        "    return f1, f2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w4nj9GQzdBrp",
        "colab_type": "text"
      },
      "source": [
        "## テストデータの読み込みと前処理"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BizqQiP6ACxl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(X_train, Y_train), (_, _) = tfk.datasets.cifar10.load_data()\n",
        "#(X_train, Y_train), (_, _) = tfk.datasets.mnist.load_data()\n",
        "x = X_train / 255 * 2 - 1\n",
        "y = Y_train.flatten()\n",
        "#x = np.expand_dims(x, axis=-1)\n",
        "gan = ConditionalDCGAN(32, 32, 3, 10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ucxy2hY_daaZ",
        "colab_type": "text"
      },
      "source": [
        "## トレーニング"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ib4LDXhwnsJI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gan.train(x, y, epochs=20)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}